# -*- coding: utf-8 -*-
"""Sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDmfluuQFEHzw81TBeZmNo9NlQ7efKP_
"""

import pandas as pd
import re

import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer as SentimentAnalyzer

nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords

from wordcloud import WordCloud
import matplotlib.pyplot as plt

df = pd.read_csv("EN.csv")

df.shape

df1 = df

df1.text = df1.text.str.lower()

df1.head()

"""Preprocessing del testo

1. Eliminazione link
"""

df1['text_processed'] = df1['text'].replace("http\S+"," ", regex = True)

"""2. Eliminazione caratteri di punteggiatura"""

df1.text_processed = df1.text_processed.replace(r'[^\w]'," ", regex = True)

"""3. Eliminazione numeri"""

df1.text_processed = df1.text_processed.replace(r'\d+'," ", regex = True)

"""4. Rimozione parole composta da una lettera"""

df1['text_processed'] = df1['text_processed'].astype(str).map(lambda x: re.sub(r'\b\w{1}\b', '', x))

"""5. Sistemazione spazi"""

df1.text_processed = df1.text_processed.replace(r'\s+'," ", regex = True)

df1.text_processed = df1.text_processed.str.lstrip()

df1.text_processed = df1.text_processed.str.rstrip()

df1.head()

"""Sentiment Analysis"""

sentiment_analyzer = SentimentAnalyzer()

def sentiment_to_label(sentiment_value):
    if( -1 <= sentiment_value <= -0.5):
      return "fortemente negativa"
    elif( -0.5 < sentiment_value < 0):
      return "negativa"
    elif(sentiment_value == 0):
      return "neutra"
    elif( 0 < sentiment_value < 0.5):
      return "positiva"
    elif(sentiment_value >= 0.5):
      return "fortemente positiva"

"""**Nairobi**"""

Nairobi = df1[df1['text'].str.contains("nairobi")]

Nairobi.shape

Nairobi = Nairobi.reset_index(drop=True)

Nairobi_sentiments = Nairobi.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Nairobi['sentiment_score'] = Nairobi_sentiments.apply(lambda sentiment: sentiment["compound"])

Nairobi.head()

Nairobi['sentiment_label'] = Nairobi['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Nairobi.head()

len(Nairobi[Nairobi['sentiment_label'] == 'fortemente negativa'])

Nairobi[Nairobi['sentiment_label'] == 'fortemente negativa'].text_processed.iloc[1]

len(Nairobi[Nairobi['sentiment_label'] == 'negativa'])

len(Nairobi[Nairobi['sentiment_label'] == 'neutra'])

len(Nairobi[Nairobi['sentiment_label'] == 'positiva'])

len(Nairobi[Nairobi['sentiment_label'] == 'fortemente positiva'])

322 + 205 + 576 + 295 + 336

"""Professore"""

Prof = df1[df1['text'].str.contains("professor")]

Prof.shape

Prof = Prof.reset_index(drop=True)
Prof.head()

Prof_sentiments = Prof.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Prof['sentiment_score'] = Prof_sentiments.apply(lambda sentiment: sentiment["compound"])

Prof['sentiment_label'] = Prof['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Prof.head()

len(Prof[Prof['sentiment_label'] == 'fortemente negativa'])

len(Prof[Prof['sentiment_label'] == 'negativa'])

len(Prof[Prof['sentiment_label'] == 'neutra'])

len(Prof[Prof['sentiment_label'] == 'positiva'])

len(Prof[Prof['sentiment_label'] == 'fortemente positiva'])

72 + 91 + 246 + 207 + 257

len(Prof)

"""Berlino"""

Berlino = df1[df1['text'].str.contains("berlin")]

Berlino.shape

Berlino = Berlino.reset_index(drop=True)
Berlino.head()

Berlin_sentiments = Berlino.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Berlino['sentiment_score'] = Berlin_sentiments.apply(lambda sentiment: sentiment["compound"])

Berlino['sentiment_label'] = Berlino['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Berlino.head()

len(Berlino[Berlino['sentiment_label'] == 'fortemente negativa'])

len(Berlino[Berlino['sentiment_label'] == 'negativa'])

len(Berlino[Berlino['sentiment_label'] == 'neutra'])

len(Berlino[Berlino['sentiment_label'] == 'positiva'])

len(Berlino[Berlino['sentiment_label'] == 'fortemente positiva'])

70 + 57 + 187 + 134 + 217

"""Tokyo"""

Tokyo = df1[df1['text'].str.contains("tokyo")]

Tokyo.shape

Tokyo = Tokyo.reset_index(drop=True)
Tokyo.head()

Tokyo_sentiments = Tokyo.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Tokyo['sentiment_score'] = Tokyo_sentiments.apply(lambda sentiment: sentiment["compound"])

Tokyo['sentiment_label'] = Tokyo['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Tokyo.head()

len(Tokyo[Tokyo['sentiment_label'] == 'fortemente negativa'])

len(Tokyo[Tokyo['sentiment_label'] == 'negativa'])

len(Tokyo[Tokyo['sentiment_label'] == 'neutra'])

len(Tokyo[Tokyo['sentiment_label'] == 'positiva'])

len(Tokyo[Tokyo['sentiment_label'] == 'fortemente positiva'])

103 + 64 + 101 + 111 + 144

"""Rio"""

Rio = df1[df1['text'].str.contains("rio")]

Rio.shape

Rio = Rio.reset_index(drop=True)
Rio.head()

Rio_sentiments = Rio.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Rio['sentiment_score'] = Rio_sentiments.apply(lambda sentiment: sentiment["compound"])

Rio['sentiment_label'] = Rio['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Berlino.head()

len(Rio[Rio['sentiment_label'] == 'fortemente negativa'])

len(Rio[Rio['sentiment_label'] == 'negativa'])

len(Rio[Rio['sentiment_label'] == 'neutra'])

len(Rio[Rio['sentiment_label'] == 'positiva'])

len(Rio[Rio['sentiment_label'] == 'fortemente positiva'])

75 + 52 + 79 + 77 + 115

"""Arturo"""

Arturo = df1[df1['text'].str.contains("arturo|arturito")]

Arturo.shape

Arturo = Arturo.reset_index(drop=True)
Arturo.head()

Arturo_sentiments = Arturo.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Arturo['sentiment_score'] = Arturo_sentiments.apply(lambda sentiment: sentiment["compound"])

Arturo['sentiment_label'] = Arturo['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Arturo.head()

len(Arturo[Arturo['sentiment_label'] == 'fortemente negativa'])

len(Arturo[Arturo['sentiment_label'] == 'negativa'])

len(Arturo[Arturo['sentiment_label'] == 'neutra'])

len(Arturo[Arturo['sentiment_label'] == 'positiva'])

len(Arturo[Arturo['sentiment_label'] == 'fortemente positiva'])

152 + 54 + 90 + 42 + 49

"""Denver"""

Denver = df1[df1['text'].str.contains("denver")]

Denver.shape

Denver = Denver.reset_index(drop=True)
Denver.head()

Denver_sentiments = Denver.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Denver['sentiment_score'] = Denver_sentiments.apply(lambda sentiment: sentiment["compound"])

Denver['sentiment_label'] = Denver['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Denver.head()

len(Denver[Denver['sentiment_label'] == 'fortemente negativa'])

len(Denver[Denver['sentiment_label'] == 'negativa'])

len(Denver[Denver['sentiment_label'] == 'neutra'])

len(Denver[Denver['sentiment_label'] == 'positiva'])

len(Denver[Denver['sentiment_label'] == 'fortemente positiva'])

39 + 23 + 71 + 65 + 96

"""Alicia Sierra"""

A_sierra = df1[df1['text'].str.contains("alicia|sierra|alicia sierra ")]

A_sierra.shape

A_sierra = A_sierra.reset_index(drop=True)
A_sierra.head()

Alicia_sentiments = A_sierra.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

A_sierra['sentiment_score'] = Alicia_sentiments.apply(lambda sentiment: sentiment["compound"])

A_sierra['sentiment_label'] = A_sierra['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
A_sierra.head()

len(A_sierra[A_sierra['sentiment_label'] == 'fortemente negativa'])

len(A_sierra[A_sierra['sentiment_label'] == 'negativa'])

len(A_sierra[A_sierra['sentiment_label'] == 'neutra'])

len(A_sierra[A_sierra['sentiment_label'] == 'positiva'])

len(A_sierra[A_sierra['sentiment_label'] == 'fortemente positiva'])

41 + 17 + 38 + 41 + 47

"""Gandia"""

Gandia = df1[df1['text'].str.contains("gandia")]
Gandia.shape

Gandia = Gandia.reset_index(drop=True)
Gandia.head()

Gandia_sentiments = Gandia.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Gandia['sentiment_score'] = Gandia_sentiments.apply(lambda sentiment: sentiment["compound"])

Gandia['sentiment_label'] = Gandia['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Gandia.head()

len(Gandia[Gandia['sentiment_label'] == 'fortemente negativa'])

len(Gandia[Gandia['sentiment_label'] == 'negativa'])

len(Gandia[Gandia['sentiment_label'] == 'neutra'])

len(Gandia[Gandia['sentiment_label'] == 'positiva'])

len(Gandia[Gandia['sentiment_label'] == 'fortemente positiva'])

92 + 35 + 37 + 39 + 19

"""Helsinki"""

Helsinki = df1[df1['text'].str.contains("helsinki")]
Helsinki.shape

Helsinki = Helsinki.reset_index(drop=True)
Helsinki.head()

Helsinki_sentiments = Helsinki.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Helsinki['sentiment_score'] = Helsinki_sentiments.apply(lambda sentiment: sentiment["compound"])

Helsinki['sentiment_label'] = Helsinki['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Helsinki.head()

len(Helsinki[Helsinki['sentiment_label'] == 'fortemente negativa'])

len(Helsinki[Helsinki['sentiment_label'] == 'negativa'])

len(Helsinki[Helsinki['sentiment_label'] == 'neutra'])

len(Helsinki[Helsinki['sentiment_label'] == 'positiva'])

len(Helsinki[Helsinki['sentiment_label'] == 'fortemente positiva'])

23 + 17 + 46 + 24 + 66

"""Palermo"""

Palermo = df1[df1['text'].str.contains("palermo")]
Palermo.shape

Palermo = Palermo.reset_index(drop=True)
Palermo.head()

Palermo_sentiments = Palermo.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Palermo['sentiment_score'] = Palermo_sentiments.apply(lambda sentiment: sentiment["compound"])

Palermo['sentiment_label'] = Palermo['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Palermo.head()

len(Palermo[Palermo['sentiment_label'] == 'fortemente negativa'])

len(Palermo[Palermo['sentiment_label'] == 'negativa'])

len(Palermo[Palermo['sentiment_label'] == 'neutra'])

len(Palermo[Palermo['sentiment_label'] == 'positiva'])

len(Palermo[Palermo['sentiment_label'] == 'fortemente positiva'])

44 + 33 + 38 + 14 + 35

"""Manila"""

Manila = df1[df1['text'].str.contains("manila")]
Manila.shape

Manila = Manila.reset_index(drop=True)
Manila.head()

Manila_sentiments = Manila.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Manila['sentiment_score'] = Manila_sentiments.apply(lambda sentiment: sentiment["compound"])

Manila['sentiment_label'] = Manila['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Manila.head()

len(Manila[Manila['sentiment_label'] == 'fortemente negativa'])

len(Manila[Manila['sentiment_label'] == 'negativa'])

len(Manila[Manila['sentiment_label'] == 'neutra'])

len(Manila[Manila['sentiment_label'] == 'positiva'])

len(Manila[Manila['sentiment_label'] == 'fortemente positiva'])

9 + 12 + 31 + 19 + 28

"""Lisbona"""

Lisbona = df1[df1['text'].str.contains("lisbona|lisbon")]
Lisbona.shape

Lisbona = Lisbona.reset_index(drop=True)
Lisbona.head()

Lisbona_sentiments = Lisbona.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Lisbona['sentiment_score'] = Lisbona_sentiments.apply(lambda sentiment: sentiment["compound"])

Lisbona['sentiment_label'] = Lisbona['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Lisbona.head()

len(Lisbona[Lisbona['sentiment_label'] == 'fortemente negativa'])

len(Lisbona[Lisbona['sentiment_label'] == 'negativa'])

len(Lisbona[Lisbona['sentiment_label'] == 'neutra'])

len(Lisbona[Lisbona['sentiment_label'] == 'positiva'])

len(Lisbona[Lisbona['sentiment_label'] == 'fortemente positiva'])

15 + 8 + 24 + 26 + 26

"""Mosca"""

Mosca = df1[df1['text'].str.contains("mosca|moscow")]

Mosca.shape

Mosca = Mosca.reset_index(drop=True)
Mosca.head()

Mosca_sentiments = Mosca.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Mosca['sentiment_score'] = Mosca_sentiments.apply(lambda sentiment: sentiment["compound"])

Mosca['sentiment_label'] = Mosca['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Mosca.head()

len(Mosca[Mosca['sentiment_label'] == 'fortemente negativa'])

len(Mosca[Mosca['sentiment_label'] == 'negativa'])

len(Mosca[Mosca['sentiment_label'] == 'neutra'])

len(Mosca[Mosca['sentiment_label'] == 'positiva'])

len(Mosca[Mosca['sentiment_label'] == 'fortemente positiva'])

19 + 4 + 18 + 13 + 23

"""Oslo"""

Oslo = df1[df1['text'].str.contains("oslo")]
Oslo.shape

Oslo = Oslo.reset_index(drop=True)
Oslo.head()

Oslo_sentiments = Oslo.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Oslo['sentiment_score'] = Oslo_sentiments.apply(lambda sentiment: sentiment["compound"])

Oslo['sentiment_label'] = Oslo['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Oslo.head()

len(Oslo[Oslo['sentiment_label'] == 'fortemente negativa'])

len(Oslo[Oslo['sentiment_label'] == 'negativa'])

len(Oslo[Oslo['sentiment_label'] == 'neutra'])

len(Oslo[Oslo['sentiment_label'] == 'positiva'])

len(Oslo[Oslo['sentiment_label'] == 'fortemente positiva'])

8 + 1 + 16 + 10 + 24

"""Bogotà"""

Bogotà = df1[df1['text'].str.contains("bogotà|bogota")]
Bogotà.shape

Bogotà = Bogotà.reset_index(drop=True)
Bogotà.head()

Bogotà_sentiments = Bogotà.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Bogotà['sentiment_score'] = Bogotà_sentiments.apply(lambda sentiment: sentiment["compound"])

Bogotà['sentiment_label'] = Bogotà['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Bogotà.head()

len(Bogotà[Bogotà['sentiment_label'] == 'fortemente negativa'])

len(Bogotà[Bogotà['sentiment_label'] == 'negativa'])

len(Bogotà[Bogotà['sentiment_label'] == 'neutra'])

len(Bogotà[Bogotà['sentiment_label'] == 'positiva'])

len(Bogotà[Bogotà['sentiment_label'] == 'fortemente positiva'])

9 + 1 + 8 + 14 + 8

"""Marsiglia"""

Marsiglia = df1[df1['text'].str.contains("marseille|marsiglia")]
Marsiglia.shape

Marsiglia = Marsiglia.reset_index(drop=True)
Marsiglia.head()

Marsiglia_sentiments = Marsiglia.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Marsiglia['sentiment_score'] = Marsiglia_sentiments.apply(lambda sentiment: sentiment["compound"])

Marsiglia['sentiment_label'] = Marsiglia['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Marsiglia.head()

len(Marsiglia[Marsiglia['sentiment_label'] == 'fortemente negativa'])

len(Marsiglia[Marsiglia['sentiment_label'] == 'negativa'])

len(Marsiglia[Marsiglia['sentiment_label'] == 'neutra'])

len(Marsiglia[Marsiglia['sentiment_label'] == 'positiva'])

len(Marsiglia[Marsiglia['sentiment_label'] == 'fortemente positiva'])

8+6+19+4+15

"""Stoccolma"""

Stoccolma = df1[df1['text'].str.contains("stoccolma|stockholm")]
Stoccolma.shape

Stoccolma = Stoccolma.reset_index(drop=True)
Stoccolma.head()

Stoccolma_sentiments = Stoccolma.text_processed.apply(lambda review: sentiment_analyzer.polarity_scores(review))

Stoccolma['sentiment_score'] = Stoccolma_sentiments.apply(lambda sentiment: sentiment["compound"])

Stoccolma['sentiment_label'] = Stoccolma['sentiment_score'].apply(lambda sentiment: sentiment_to_label(sentiment))
Stoccolma.head()

len(Stoccolma[Stoccolma['sentiment_label'] == 'fortemente negativa'])

len(Stoccolma[Stoccolma['sentiment_label'] == 'negativa'])

len(Stoccolma[Stoccolma['sentiment_label'] == 'neutra'])

len(Stoccolma[Stoccolma['sentiment_label'] == 'positiva'])

len(Stoccolma[Stoccolma['sentiment_label'] == 'fortemente positiva'])

14+4+11+9+3

"""Risultati"""

Personaggio = ['Nairobi', 'Professore', 'Berlino', 'Tokyio', 'Rio', 'Arturo', 'Denver', 'Alicia Sierra', 'Gandia', 'Helsinki', 'Palermo', 'Manila',
               'Lisbona', 'Mosca', 'Oslo', 'Bogotà', 'Marsiglia', 'Stoccolma']
Fortemente_negativo = [322, 72, 70, 103, 75, 152, 39, 41, 92, 23, 44, 9, 15, 19, 8, 9, 8, 14]
Negativo = [205, 91, 57, 64, 52, 54, 23, 17, 35, 17, 33, 12, 8, 4, 1, 1, 6, 4]
Neutro = [576, 246, 187, 101, 79, 90, 71, 38, 37, 46, 38, 31, 24, 18, 16, 8, 19, 11]
Positivo = [295, 207, 134, 111, 77, 42, 65, 41, 39, 24, 14, 19, 26, 13, 10, 14, 4, 9]
Fortemente_positivo = [336, 257, 217, 144, 115, 49, 96, 47, 19, 66, 35, 28, 26, 23, 24, 8, 15, 3]
N_tweet = [1734, 873, 665, 523, 398, 387, 294, 184, 222, 176, 164, 99, 99, 77, 59, 40, 52, 41]

list_of_tuples = list(zip(Personaggio, Fortemente_negativo, Negativo, Neutro, Positivo, Fortemente_positivo, N_tweet))

risultati = pd.DataFrame(list_of_tuples, columns = ['Personaggio', "Fortemente_negativo", "Negativo", "Neutro", "Positivo", "Fortemente_positivo",
                                                    "N_tweet"])
risultati

"""Stacked barchart"""

category_labels = risultati.Personaggio

risultati.tail()

prova = risultati

"""Calcolo percentuali"""

totals = [i+j+k+l+m for i,j,k,l,m in zip(prova['Fortemente_negativo'], prova['Negativo'], prova['Neutro'], prova['Positivo'], prova['Fortemente_positivo'])]

totals

F_neg = [i / j * 100 for i,j in zip(prova['Fortemente_negativo'], totals)]

Neg = [i / j * 100 for i,j in zip(prova['Negativo'], totals)]

Neu = [i / j * 100 for i,j in zip(prova['Neutro'], totals)]

Pos = [i / j * 100 for i,j in zip(prova['Positivo'], totals)]

F_pos = [i / j * 100 for i,j in zip(prova['Fortemente_positivo'], totals)]

F_pos[17]

import numpy as np
import matplotlib.pyplot as plt


category_names = ['Fortemente negativo', "Negativo", "Neutro", "Positivo", 'Fortemente positivo']
results = {
    'Nairobi': [19, 12, 33, 17, 19],
    'Professore': [9, 10, 28, 24, 29],
    'Berlino':[11, 9, 27, 20, 33], 
    'Tokyio':[20, 12, 19, 21, 28], 
    'Rio': [19, 13, 20, 19, 29],
    'Arturo': [39, 14, 23, 11, 13],
    'Denver': [13, 8, 24, 22, 33], 
    'Alicia Sierra': [22, 9, 21, 22, 26],
    'Gandia': [41, 16, 16, 18, 9], 
    'Helsinki': [13, 10, 25, 14, 38],
    'Palermo': [27, 20, 23, 9, 21], 
    'Manila': [9, 12, 32, 19, 28],
    'Lisbona': [15, 8, 24, 26, 27],
    'Mosca': [25, 5, 23, 17, 30],
    'Oslo': [14, 2, 26, 17, 41],
    'Bogotà': [23, 3, 19, 35, 20],
    'Marsiglia': [15, 12, 36, 8, 29],
    'Stoccolma': [34, 10, 27, 22, 7]
}


def survey(results, category_names):
    labels = list(results.keys())
    data = np.array(list(results.values()))
    data_cum = data.cumsum(axis=1)
    category_colors = plt.get_cmap('RdYlGn')(
        np.linspace(0.15, 0.85, data.shape[1]))

    fig, ax = plt.subplots(figsize=(9.2, 7))
    ax.invert_yaxis()
    ax.xaxis.set_visible(False)
    ax.set_xlim(0, np.sum(data, axis=1).max())

    for i, (colname, color) in enumerate(zip(category_names, category_colors)):
        widths = data[:, i]
        starts = data_cum[:, i] - widths
        ax.barh(labels, widths, left=starts, height=0.5,
                label=colname, color=color)
        xcenters = starts + widths / 2

        r, g, b, _ = color
        text_color = 'white' if r * g * b < 0.5 else 'darkgrey'
        for y, (x, c) in enumerate(zip(xcenters, widths)):
            ax.text(x, y, str(int(c)), ha='center', va='center',
                    color=text_color)
    ax.legend(ncol=len(category_names), bbox_to_anchor=(0, 1),
              loc='lower left', fontsize='small')

    return fig, ax


survey(results, category_names)
#plt.savefig('Sentiment_personaggi.png')
plt.show()
